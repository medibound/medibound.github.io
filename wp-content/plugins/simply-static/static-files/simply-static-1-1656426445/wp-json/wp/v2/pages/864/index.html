{"id":864,"date":"2021-12-12T07:05:52","date_gmt":"2021-12-12T07:05:52","guid":{"rendered":"https:\/\/localhost\/medibound\/?page_id=864"},"modified":"2022-06-28T14:27:08","modified_gmt":"2022-06-28T14:27:08","slug":"project","status":"publish","type":"page","link":"https:\/\/localhost\/medibound\/project\/","title":{"rendered":"Projects"},"content":{"rendered":"\t\t<div data-elementor-type=\"wp-page\" data-elementor-id=\"864\" class=\"elementor elementor-864\" data-elementor-settings=\"[]\">\n\t\t\t\t\t\t\t<div class=\"elementor-section-wrap\">\n\t\t\t\t\t\t\t<section class=\"elementor-section elementor-top-section elementor-element elementor-element-649c61b elementor-section-boxed elementor-section-height-default elementor-section-height-default\" data-id=\"649c61b\" data-element_type=\"section\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-135853e\" data-id=\"135853e\" data-element_type=\"column\">\n\t\t\t<div class=\"elementor-widget-wrap\">\n\t\t\t\t\t\t\t\t\t<\/div>\n\t\t<\/div>\n\t\t\t\t\t\t\t<\/div>\n\t\t<\/section>\n\t\t\t\t<section class=\"elementor-section elementor-top-section elementor-element elementor-element-7d9b261 elementor-section-boxed elementor-section-height-default elementor-section-height-default\" data-id=\"7d9b261\" data-element_type=\"section\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-57011c7\" data-id=\"57011c7\" data-element_type=\"column\">\n\t\t\t<div class=\"elementor-widget-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-element elementor-element-220a321 elementor-widget elementor-widget-spacer\" data-id=\"220a321\" data-element_type=\"widget\" data-widget_type=\"spacer.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"><\/div>\n\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t<\/div>\n\t\t<\/div>\n\t\t\t\t\t\t\t<\/div>\n\t\t<\/section>\n\t\t\t\t<section class=\"elementor-section elementor-top-section elementor-element elementor-element-fa1955f elementor-section-boxed elementor-section-height-default elementor-section-height-default\" data-id=\"fa1955f\" data-element_type=\"section\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-b0b9eee\" data-id=\"b0b9eee\" data-element_type=\"column\">\n\t\t\t<div class=\"elementor-widget-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-element elementor-element-9253465 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"9253465\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">PROJECT<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-1995c72 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"1995c72\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">SCIENCE FAIR<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-d44c4f1 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"d44c4f1\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">USES MEDIBOUND<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-73bc8d6 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"73bc8d6\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">WORKS WITH MOBILE<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-5c0f7e7 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"5c0f7e7\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h2 class=\"elementor-heading-title elementor-size-default\">Comparing the Efficiency of Novel Point of Care Approaches to Identifying Specific Stages of Diabetic Retinopathy Through the Use of Low-Cost Neural Networks and Deep Learning Solutions\n<\/h2>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-755c59e elementor-widget__width-inherit elementor-widget elementor-widget-heading\" data-id=\"755c59e\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">A Novel Study Conducted By Nicholas Harty and Aum Dhruv - (2021-2022)<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-acef8af elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"acef8af\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h4 class=\"elementor-heading-title elementor-size-default\">Prerequisites:<\/h4>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<section class=\"elementor-section elementor-inner-section elementor-element elementor-element-96bd76d elementor-section-full_width elementor-section-height-default elementor-section-height-default\" data-id=\"96bd76d\" data-element_type=\"section\" data-settings=\"{&quot;background_background&quot;:&quot;classic&quot;}\">\n\t\t\t\t\t\t<div class=\"elementor-container elementor-column-gap-default\">\n\t\t\t\t\t<div class=\"elementor-column elementor-col-50 elementor-inner-column elementor-element elementor-element-d0d738c\" data-id=\"d0d738c\" data-element_type=\"column\">\n\t\t\t<div class=\"elementor-widget-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-element elementor-element-60f0e12 elementor-widget elementor-widget-heading\" data-id=\"60f0e12\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h6 class=\"elementor-heading-title elementor-size-default\">EyePACS DR Retinal Imaging Classification Library<\/h6>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-dbc28f2 elementor-icon-list--layout-traditional elementor-list-item-link-full_width elementor-widget elementor-widget-icon-list\" data-id=\"dbc28f2\" data-element_type=\"widget\" data-widget_type=\"icon-list.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<ul class=\"elementor-icon-list-items\">\n\t\t\t\t\t\t\t<li class=\"elementor-icon-list-item\">\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-icon\">\n\t\t\t\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-arrow-alt-circle-right\"><\/i>\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-text\">0 - No Diabetic Retinopathy<\/span>\n\t\t\t\t\t\t\t\t\t<\/li>\n\t\t\t\t\t\t\t\t<li class=\"elementor-icon-list-item\">\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-icon\">\n\t\t\t\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-arrow-alt-circle-right\"><\/i>\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-text\">1 - Mild Diabetic Retinopathy<\/span>\n\t\t\t\t\t\t\t\t\t<\/li>\n\t\t\t\t\t\t\t\t<li class=\"elementor-icon-list-item\">\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-icon\">\n\t\t\t\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-arrow-alt-circle-right\"><\/i>\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-text\">2 - Moderate Diabetic Retinopathy<\/span>\n\t\t\t\t\t\t\t\t\t<\/li>\n\t\t\t\t\t\t\t\t<li class=\"elementor-icon-list-item\">\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-icon\">\n\t\t\t\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-arrow-alt-circle-right\"><\/i>\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-text\">3 - Severe Diabetic Retinopathy<\/span>\n\t\t\t\t\t\t\t\t\t<\/li>\n\t\t\t\t\t\t\t\t<li class=\"elementor-icon-list-item\">\n\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-icon\">\n\t\t\t\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-arrow-alt-circle-right\"><\/i>\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-icon-list-text\">4 - Proliferative Diabetic Retinopathy<\/span>\n\t\t\t\t\t\t\t\t\t<\/li>\n\t\t\t\t\t\t<\/ul>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t<\/div>\n\t\t<\/div>\n\t\t\t\t<div class=\"elementor-column elementor-col-50 elementor-inner-column elementor-element elementor-element-8a01899\" data-id=\"8a01899\" data-element_type=\"column\">\n\t\t\t<div class=\"elementor-widget-wrap elementor-element-populated\">\n\t\t\t\t\t\t\t\t<div class=\"elementor-element elementor-element-bf15d9c elementor-align-right elementor-widget elementor-widget-button\" data-id=\"bf15d9c\" data-element_type=\"widget\" data-widget_type=\"button.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-button-wrapper\">\n\t\t\t<a href=\"https:\/\/storage.googleapis.com\/kaggle-competitions-data\/kaggle-v2\/4104\/46661\/bundle\/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&#038;Expires=1643692870&#038;Signature=gRaOfJjKkMa4X7Z2FgOR%2FEgQ4S4fvY0RnHVQNxnjZNHgDIfmvuz8bVHdmg35xbaw81Er4W374chQRbQahzqJN8xjbiZD0MN6pttyxtQ8ONvW9vaFKUV4M7jCky9Rm8tuQydm5qdjDPBWANJ1WPzvbmlk9CRaArRYufKhHMy2%2FOkuZ2W8yv6%2FW7E4zRiMbQsftXuYnRZr9iar%2B1RcSyAZgqgPqeMub9UPsFaKevsC%2BtdaKwJwOfuHZhPOnI3EwEzjmF7lHD4v%2B5DsRut6N1%2FifizcedZsHCfV0DnVpKYeK1h3pZQZL%2BVSyOohugI2InCj%2BUmpmBbwcpQf7FsTnT9pxQ%3D%3D&#038;response-content-disposition=attachment%3B+filename%3Ddiabetic-retinopathy-detection.zip\" class=\"elementor-button-link elementor-button elementor-size-md\" role=\"button\">\n\t\t\t\t\t\t<span class=\"elementor-button-content-wrapper\">\n\t\t\t\t\t\t<span class=\"elementor-button-icon elementor-align-icon-left\">\n\t\t\t\t<i aria-hidden=\"true\" class=\"fas fa-download\"><\/i>\t\t\t<\/span>\n\t\t\t\t\t\t<span class=\"elementor-button-text\">Download Training Retinal ImageSet (88.29 GB)<\/span>\n\t\t<\/span>\n\t\t\t\t\t<\/a>\n\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t<\/div>\n\t\t<\/div>\n\t\t\t\t\t\t\t<\/div>\n\t\t<\/section>\n\t\t\t\t<div class=\"elementor-element elementor-element-285e7c5 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"285e7c5\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h4 class=\"elementor-heading-title elementor-size-default\">Experimental Utility (JS):<\/h4>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-6e9486f elementor-widget elementor-widget-toggle\" data-id=\"6e9486f\" data-element_type=\"widget\" data-widget_type=\"toggle.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-toggle\" role=\"tablist\">\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-1151\" class=\"elementor-tab-title\" data-tab=\"1\" role=\"tab\" aria-controls=\"elementor-tab-content-1151\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\"> Train The Model<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-1151\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"1\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-1151\"><iframe scrolling=\"no\" src=\"..\/image\/Sample\/index.html\" id=\"child-iframe2\" onload=\"loadCustom2()\" seamless=\"true\"><\/iframe>\n<script>\nfunction loadCustom2() {\n\tlet iframe = document.querySelector(\"#child-iframe2\");\n\n\t\tsetInterval(function() {\n\t\t\tiframe.height = iframe.contentDocument.body.scrollHeight + 20;\n});\n\n}\n<\/script><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-1152\" class=\"elementor-tab-title\" data-tab=\"2\" role=\"tab\" aria-controls=\"elementor-tab-content-1152\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\"> Test  The Model<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-1152\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"2\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-1152\"><iframe scrolling=\"no\" src=\"..\/image\/Sample\/test.html\" id=\"child-iframe\" onload=\"loadCustom()\" seamless=\"true\"><\/iframe>\n<script>\nfunction loadCustom() {\n\tlet iframe = document.querySelector(\"#child-iframe\");\n\n\t\tsetInterval(function() {\n\t\t\tiframe.height = iframe.contentDocument.body.scrollHeight + 50;\n});\n\n}\n<\/script><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-16f8601 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"16f8601\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h4 class=\"elementor-heading-title elementor-size-default\">Methods, Procedures, and Analysis:<\/h4>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-1556560 elementor-widget elementor-widget-toggle\" data-id=\"1556560\" data-element_type=\"widget\" data-widget_type=\"toggle.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-toggle\" role=\"tablist\">\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2231\" class=\"elementor-tab-title\" data-tab=\"1\" role=\"tab\" aria-controls=\"elementor-tab-content-2231\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Variables<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2231\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"1\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2231\"><div>\n<strong>Independent:\u00a0<\/strong>\n<ul>\n \t<li><span style=\"font-weight: 400;\">Training sample sizes (intervals at 125, 250, 375, 500, 1000, 1500, 2000, 2500)\u00a0<\/span><\/li>\n \t<li><span style=\"font-weight: 400;\">Type of NN algorithm<\/span><\/li>\n<\/ul>\n<strong>Dependent:\u00a0<\/strong>\n<ul>\n \t<li><span style=\"font-weight: 400;\">Accuracy of each trial\u00a0<\/span><\/li>\n \t<li><span style=\"font-weight: 400;\">Correlation between training sample size and mean accuracy\u00a0<\/span><\/li>\n \t<li><span style=\"font-weight: 400;\">Difference between CNN and KNN with increasing sample sizes (line graph)<\/span><\/li>\n<\/ul>\n<strong>Control:<\/strong>\n<ul>\n \t<li><span style=\"font-weight: 400;\">Database of images<\/span><\/li>\n \t<li><span style=\"font-weight: 400;\">Number of testing trials (10 trials with 100 unseen samples) <\/span><\/li>\n<\/ul>\n<\/div>\n<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2232\" class=\"elementor-tab-title\" data-tab=\"2\" role=\"tab\" aria-controls=\"elementor-tab-content-2232\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Materials<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2232\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"2\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2232\"><div><ul><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Retinal Dataset (EyePACS\/Google Retinal Dataset -&gt; Download Above)<\/span><\/li><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">TensorFlow API (through <a href=\"https:\/\/ml5js.org\/\">ml5.js<\/a> library)<\/span><\/li><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Computing Utility (Chrome Capable Device)<\/span><\/li><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Data Sheet Recording Software<\/span><\/li><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">External Graphing Software (Statistical Analysis)<\/span><\/li><li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">Online Testing Portal that allows for the Virtual Testing of the Researchers\u2019 Algorithms<\/span><\/li><\/ul><\/div><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2233\" class=\"elementor-tab-title\" data-tab=\"3\" role=\"tab\" aria-controls=\"elementor-tab-content-2233\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Assumptions\/Biases and Limitations<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2233\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"3\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2233\"><div>\n<span style=\"font-weight: 400;\">While KNN and CNN algorithms are of similar structure, there are differences that may act as a limitation. The main difference between the convolutional neural network algorithm and the k-nearest neighbors algorithm exists in their ability to discern between distinct features of an image. The convolutional neural network algorithm processes feature regardless of spatial orientation because of its utilization of kernels that process training images while the k-nearest neighbors algorithm identifies features based upon color\/intensity and takes spatial orientation into account when classifying testing images. Another difference exists in their individual training processes. The k-nearest neighbors algorithm trains upon its sample dataset by conforming the data into logit-based matrices which requires little computational power as it simply is building a record\/ledger for later classification. On the other hand, the convolutional neural network algorithm uses higher computational power in its training process as it cycles through multiple Convolutional Layers as well as the refinement of its feature identification across a series of predefined epochs.\u00a0<\/span>\n<ul>\n \t<li><span style=\"font-weight: 400;\">Although these two algorithms are mathematically distinct in almost every component of their individual function, their output, in terms of correlation, are the same and they share similar efficiency when tasked with the training\/classification of bitmapped medical datasets, hence the comparison is justified.<\/span><\/li>\n<\/ul>\n&nbsp;\n\n<span style=\"font-weight: 400;\">In conditions with a lower sample count, KNN and CNN algorithms may output a greater spread of results due to less of a dataset to work with.\u00a0<\/span>\n<ul>\n \t<li style=\"font-weight: 400;\" aria-level=\"1\"><span style=\"font-weight: 400;\">In order to combat this, the researchers incorporated multiple sample sizes.<\/span><\/li>\n<\/ul>\n&nbsp;\n\n<span style=\"font-weight: 400;\">The essential assumptions of the investigators\u2019 study include that the initial dataset, conceived through EyePACS\u2019s diabetic retinopathy study, was accurate in the classifications provided by physicians. Another assumption can be that the algorithms are accurately established to produce equal probabilities in fundamental testing (see \u201cMethods\u201d for more information). An assumption for the replication of the investigators\u2019 study can be seen in the equality of hardware across testing. This ensured equal distribution of RAM (1GB) and CPU clock speed (locked at 1.4 GHz). The final major assumption made in experimentation comes in the form of equality across sample bitmap dimensions. Each image within the investigators\u2019 dataset was minimized down to a 250px by 250px bitmap to ensure efficiency within testing. In a system that undergoes experimental procedures with higher input dimensions, the probabilities could differ based on the new fidelity of the developed feature-set.\u00a0 <\/span>\n<be>\n<\/div>\n<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2234\" class=\"elementor-tab-title\" data-tab=\"4\" role=\"tab\" aria-controls=\"elementor-tab-content-2234\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Methods<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2234\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"4\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2234\"><p><strong>Data Training Collection:<\/strong><\/p><p><span style=\"font-weight: 400;\">The researchers collected data from EyePACS, an organization that provided access to multiple retinal images classified by different stages of severity. The stages consisted of \u201cno present diabetic retinopathy\u201d, \u201cmild diabetic retinopathy\u201d, \u201cmoderate diabetic retinopathy\u201d, \u201csevere diabetic retinopathy\u201d, and \u201cproliferative diabetic retinopathy.\u201d 250 randomly selected images were taken out of the sample to later be used for testing. To reduce bias, researchers also incorporated random sampling in training the k-nearest neighbors model and convolutional neural network model. Both neural network models were trained to a random sample of 25 images for each stage (totaling 125 retinal images), 50 images for each stage (totaling 250 images), 75 images for each stage (totaling 375 images), 100 images for each stage (totaling 500 images), 200 images for each stage (totaling 1000 images), 300 images for each stage (totaling 1500 images), 400 images for each stage (totaling 2000 images), and 500 images for each stage (totaling 2500 images).<\/span><\/p><p><strong>Data Processing:<\/strong><\/p><p><span style=\"font-weight: 400;\">The data was processed through its raw form into composed tables that discerned between probabilities as related to the specific instance of trial and the severity of diabetic retinopathy (DR) provided in the sample image. From this point, the data is converted to be displayed within two radar graphs (as well as two bar graphs) that display the size\/area exchange across the change in training sample sizes within each individual DR severity. The data from algorithms is then composed into two lines graphs: one displaying the raw mean accuracy across the change in training sample size and the other displaying the buffered mean accuracy across the change in training sample size.<\/span><\/p><p><strong>Algorithm Design\/Accuracy:\u00a0<\/strong><\/p><p><span style=\"font-weight: 400;\">The KNN and CNN algorithms were designed to develop and run within a standard web\/HTML environment. This environment was specifically selected to broaden the accessibility of the software to all modern hardware across most operating systems (although the investigators conducted all logistic experimentation on hardware of equal limitations). These algorithms were developed through TensorFlow API in tandem with the javascript library \u201cml5.js\u201d to develop a competent web utility. The fundamental design of these algorithms was reliant upon the constraints provided by the investigators. These constraints were balanced through preliminary testing to assure essential equality of outcome. This outcome came in the form of image classification probabilities and the image datasets used for this balancing act were provided by Google in the form of the TensorFlow 64&#215;64 Clothing dataset (the usage of this dataset was based on the recommendation of data scientists in relation to TensorFlow). This data provided a standardized reference point for how to balance these algorithms and much of the adjustment occurred in the altering of the epoch count in the CNN program. Unlike the KNN algorithm that quickly builds a ledger of logits in its training procedures, CNN undergoes a series of training trials to perfect its feature identification. The number of allowed epochs would shift the basic equality of these algorithms at a fundamental level. The researchers found that ~50 epochs within CNN training were enough to assure equality in fundamental testing. This allowed precision within the investigators\u2019 experimentation when it came to identifying areas of the difference without the bias of adjustable internal factors. This aided in securing a design that was stable in testing and worthy of true statistical comparison.\u00a0<\/span><\/p><p><strong>Data Testing Collection:\u00a0<\/strong><\/p><p><span style=\"font-weight: 400;\">Prior to training the neural network models, 250 images were taken out of the sample data collected from EyePACS. In each trial, a random sample of 25 images was tested on each trained neural network for both models, for a total of 10 trials. This process was duplicated for each severity level, in total, to utilize 1250 images in testing with a combination of 50 net trials over the 5 severities.<\/span><\/p><p><strong>Statistical Background:\u00a0<\/strong><\/p><p><span style=\"font-weight: 400;\">The investigators collected a combination of nominal (type of algorithm, type of training sample size, and DR severity) and ratio data (accuracy). The type of training sample size consisted of n=125, n=250, n=375, n=500, n=1000, n=1500, n=2000, and n=2500. The stages of DR severity consisted of \u201cno present diabetic retinopathy\u201d, \u201cmild diabetic retinopathy\u201d, \u201cmoderate diabetic retinopathy\u201d, \u201csevere diabetic retinopathy\u201d, and \u201cproliferative diabetic retinopathy.\u201d The investigators\u2019 data examined the relationship between the type of algorithm and accuracy, for different training sample sizes in identifying specific stages of diabetic retinopathy in retinal images. For each type of training sample size, researchers incorporated an independent measures design in which different retinal images were used per trial, and the quantitative variable (accuracy) was measured in reference to two categorical variables (type of algorithm and DR severity). Because of this, a two-way ANOVA test (analysis of variance) with a significance level (\u03b1) of 0.05 was used to determine the experiment\u2019s statistical significance.<\/span><\/p><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2235\" class=\"elementor-tab-title\" data-tab=\"5\" role=\"tab\" aria-controls=\"elementor-tab-content-2235\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Procedure<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2235\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"5\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2235\"><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>1.<\/strong> Researchers should prepare a modern internet computing device.<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>2.<\/strong> After doing so, open up a browser to run the neural networks. Google Chrome, Firefox, or any other browser will work.<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>3.<\/strong> Go to the Search tab and type up the link: \u201dmedibound.com\/project\u201d. Click enter. This website is programmed to run and compare the available neural networks based upon an uploaded graphic of a retinal 20D image. Upload the training sample images to the \u201cTrain The Model\u201d dropdown with an interval of n = 125, 250, 375, 500, 1000, 1500, 2000, 2500.\u00a0 Following this upload, activate the training module and download the appropriate Neural Network models (3 for CNN, 1 for KNN).<\/span><\/p><p style=\"padding-left: 80px;\"><b><span style=\"font-weight: 400;\">a.) <\/span>[OR] Alternative Ground-Up Development Plan:<\/b><span style=\"font-weight: 400;\">\u00a0<\/span><\/p><p style=\"padding-left: 120px;\"><span style=\"font-weight: 400;\">i.) Develop two contrasting neutral networks (a CNN configuration and a KNN configuration) within Kera\u2019s TensorFlow architecture creator.\u00a0<\/span><\/p><p style=\"padding-left: 120px;\"><span style=\"font-weight: 400;\">ii.) Ensure that the following constraints are provided to the CNN algorithm:<\/span><\/p><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">Debug = true<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">Inputs = [64 (px), 64 (px), 4]<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">Task: &#8216;imageClassification&#8217;,<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">Epochs = 50<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><p style=\"padding-left: 120px;\"><span style=\"font-weight: 400;\">iii.) Ensure that the following constraints are provided to the KNN algorithm:<\/span><\/p><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">K = Auto<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"list-style-type: none;\"><ul><li style=\"font-weight: 400;\" aria-level=\"4\"><i><span style=\"font-weight: 400;\">Debug = true<\/span><\/i><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><\/li><\/ul><p style=\"padding-left: 120px;\"><span style=\"font-weight: 400;\">iv.) Upload the training sample images to the \u201cTraining\u201d dropdown with an interval of n = 125, 250, 375, 500, 1000, 1500, 2000, 2500.\u00a0 Following this upload, activate the training module and download the appropriate Neural Network models for each interval of sample images (3 for each CNN, 1 for each KNN, 32 in total)<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>4.<\/strong> After storing the models from the training module, go to \u201dproject.medibound.com\u201d on the web and select the \u201cTest The Model\u201d dropdown.<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>5.<\/strong> Insert 25 for the \u201cRandom Sample Size per Individual Trial Group (# of Images)\u201d and distribute 250 testing retinal images into each severity category in \u201cTesting Samples\u201d.\u00a0<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>6.<\/strong> From this point, upload both of the model sets received from the training model for a specific training sample size and insert the corresponding training sample size under \u201cSample Size of Training Group (# of Images)\u201d<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>7.<\/strong> Confirm that all data has been recorded. If any data is missing, redo that part of the neural network testing.<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\"><strong>8.<\/strong> Repeat Steps 6 and 7 until all training sample size models are experimented upon and properly recorded.<\/span><\/p><p style=\"padding-left: 40px;\"><span style=\"font-weight: 400;\">9. Analyze and format all collected data.<\/span><\/p><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2236\" class=\"elementor-tab-title\" data-tab=\"6\" role=\"tab\" aria-controls=\"elementor-tab-content-2236\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Interpretation of Data<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2236\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"6\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2236\"><p><b>Results<\/b><\/p><p><span style=\"font-weight: 400;\">To measure the accuracy of the CNN and KNN algorithms, mean and buffered accuracy was calculated for each training sample size. For both algorithms, the mean accuracy (%) was the average of all 50 trials (10 per DR severity). The buffered accuracy (%) provided a 1-severity margin to either end of the definite outcome, resulting in an amplified marker of the mean accuracy. In a training sample size of 125 retinal images (ranging in severity), the CNN algorithm resulted in a mean accuracy of 19.36% and a buffered accuracy of 48.00%, while the KNN algorithm resulted in a mean accuracy of 20.36% and a buffered accuracy of 50.00%. In a training sample size of 250 retinal images, the CNN algorithm resulted in a mean accuracy of 20.08% and a buffered accuracy of 52.00%, while the KNN algorithm resulted in a mean accuracy of 20.80% and a buffered accuracy of 54.00%. In a training sample size of 375 retinal images, the CNN algorithm resulted in a mean accuracy of 22.88% and a buffered accuracy of 56.00%, while the KNN algorithm resulted in a mean accuracy of 21.84% and a buffered accuracy of 54.50%. In a training sample size of 500 retinal images, the CNN algorithm resulted in a mean accuracy of 22.88% and a buffered accuracy of 56.44%, while the KNN algorithm resulted in a mean accuracy of 22.32% and a buffered accuracy of 54.56%. In a training sample size of 1000 retinal images, the CNN algorithm resulted in a mean accuracy of 25.60% and a buffered accuracy of 58.00%, while the KNN algorithm resulted in a mean accuracy of 24.68% and a buffered accuracy of 55.00%. In a training sample size of 1500 retinal images, the CNN algorithm resulted in a mean accuracy of 29.04% and a buffered accuracy of 59.00%, while the KNN algorithm resulted in a mean accuracy of 25.20% and a buffered accuracy of 56.00%. In a training sample size of 2000 retinal images, the CNN algorithm resulted in a mean accuracy of 30.64% and a buffered accuracy of 62.00%, while the KNN algorithm resulted in a mean accuracy of 25.20% and a buffered accuracy of 56.22%. In a training sample size of 2500 retinal images, the CNN algorithm resulted in a mean accuracy of 32.16% and a buffered accuracy of 63.33%, while the KNN algorithm resulted in a mean accuracy of 26.64% and a buffered accuracy of 57.00%.<\/span><\/p><p><b>Trends<\/b><\/p><p><span style=\"font-weight: 400;\">In both algorithms, there was a general increase in accuracy as the training sample size increased. In the CNN algorithm, this increase was steeper compared to the KNN algorithm. This trend can be noted in the slope of the provided line graphs. In addition to this, the radar graphs and bar graphs highlighted individual upward trends in each category of diabetic retinopathy by increasing sample size. From the line graphs, the pattern of CNN\u2019s spike is evident as the CNN mean accuracy line makes a sharp increase at around 375 samples and in doing so, surpasses the mean accuracy of KNN.<\/span><\/p><p><b>Significance<\/b><\/p><p><span style=\"font-weight: 400;\">When presented with training sample sizes of 125 and 250 retinal images, KNN was more accurate, which could justify its use over CNN in lower sample sizes. However, in training sample sizes of n=375 and above, CNN was more accurate, which could justify its use over KNN in higher sample sizes. This supported the investigators\u2019 hypothesis since the CNN algorithm produced a greater average accuracy across higher training sample sizes in this identification process compared to the KNN algorithm, which produced greater average accuracy across lower training sample sizes. At the largest training sample size of 2500 retinal images, the CNN was over 6% higher in accuracy compared to KNN. This could signify that CNN\u2019s accuracy would continue growing at a higher rate with additional training samples. This acknowledgment could prove to be beneficial to larger researchers with worldwide resources.\u00a0<\/span><\/p><p><b>Statistical Analysis<\/b><\/p><p><span style=\"font-weight: 400;\">The investigators collected a combination of nominal (type of algorithm, type of training sample size, and DR severity) and ratio data (accuracy). Their data examined the relationship between the type of algorithm and accuracy, for different training sample sizes in identifying specific stages of diabetic retinopathy in retinal images. For each type of training sample size, researchers incorporated an independent measures design in which different retinal images were used per trial, and the quantitative variable (accuracy) was measured in reference to two categorical variables (type of algorithm and DR severity). Because of this, a two-way ANOVA test (analysis of variance) with a significance level (\u03b1) of 0.05 was used to determine the experiment\u2019s statistical significance. For a training sample size of 125 retinal images, the ANOVA test generated an interaction p-value of 0.0001347. For a training sample size of 250 retinal images, the ANOVA test generated an interaction p-value of 0.0002419. For a training sample size of 375 retinal images, the ANOVA test generated an interaction p-value of 0.0001786. For a training sample size of 500 retinal images, the ANOVA test generated an interaction p-value of 0.01463. For a training sample size of 1000 retinal images, the ANOVA test generated an interaction p-value of 0.000272. For a training sample size of 1500 retinal images, the ANOVA test generated an interaction p-value of 0.000077. For a training sample size of 2000 retinal images, the ANOVA test generated an interaction p-value of 0.00001857. For a training sample size of 2500 retinal images, the ANOVA test generated an interaction p-value of 0.0002475. All of the p-values from the ANOVA test were less than the significance level of 0.05, which meant the null hypothesis, that there is no statistical significance between the type of algorithm and its average accuracy across training sample sizes, was rejected. This signifies that there is a statistically significant relationship. In addition to this, the residuals followed a normal distribution as shown by the Q-Q plot. Furthermore, every interaction priori power generated by the ANOVA test was greater than 0.9850, signifying that the results are likely valid.<\/span><\/p><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-2237\" class=\"elementor-tab-title\" data-tab=\"7\" role=\"tab\" aria-controls=\"elementor-tab-content-2237\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Conclusion and Discussion<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-2237\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"7\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-2237\"><p><span style=\"font-weight: 400;\">When presented with training sample sizes of 125 and 250 retinal images, KNN was more accurate, which could justify its use over CNN in lower sample sizes. However, in training sample sizes of n=375 and above, CNN was more accurate, which could justify its use over KNN in higher sample sizes. This supported the investigators\u2019 hypothesis since the CNN algorithm produced a greater average accuracy across higher training sample sizes in this identification process compared to the KNN algorithm, which produced greater average accuracy across lower training sample sizes. At the largest training sample size of 2500 retinal images, the CNN was over 6% higher in accuracy compared to KNN. This signifies that CNN\u2019s accuracy could continue growing at a higher rate with additional training samples. This acknowledgment could prove to be beneficial to larger researchers with worldwide resources.\u00a0<\/span><\/p><p><span style=\"font-weight: 400;\">For each training sample size, the two-way ANOVA test conducted by the researchers generated p-values less than the significance level of 0.05, which meant the null hypothesis, that there is no statistical significance between the type of algorithm and its average accuracy across training sample sizes, was rejected. From this, it can be concluded that there is a statistically significant relationship between the type of algorithm and accuracy in identifying specific stages of diabetic retinopathy in retinal images. This means that the type of algorithm played a role in its accuracy, and wasn\u2019t due to chance, proving that the results are likely valid.<\/span><\/p><p><span style=\"font-weight: 400;\">These results concur with the community of global issues for which this study was conducted upon. The research and findings of this study will directly aid low-income exhibitions that seek widespread testing for the preventable disease that is diabetic retinopathy. With the data in relation to KNN and CNN, as far as ambiguity in the outcome, the investigators have provided some certainty to the usage of such efficient algorithms within medical treatment. Although ambiguity still lies in the perfection of accuracy within the two computing models, the researchers have provided a defining line between the necessary usage of KNN and CNN in the field. When granted further retinal samples, this study recommends the development of a convolutional neural network to best discern between DR severities. However, when granted fewer retinal samples (n\u2264250), this study suggests k-nearest neighbors as the more accurate, although not precise, algorithm to best discern between DR severities. <\/span><\/p><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-66fb824 elementor-widget__width-auto elementor-widget elementor-widget-heading\" data-id=\"66fb824\" data-element_type=\"widget\" data-widget_type=\"heading.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t<h4 class=\"elementor-heading-title elementor-size-default\">Other Information:<\/h4>\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-21d3e61 elementor-widget elementor-widget-toggle\" data-id=\"21d3e61\" data-element_type=\"widget\" data-widget_type=\"toggle.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-toggle\" role=\"tablist\">\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-3541\" class=\"elementor-tab-title\" data-tab=\"1\" role=\"tab\" aria-controls=\"elementor-tab-content-3541\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Abstract<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-3541\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"1\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-3541\"><p><a href=\"http:\/\/medibound.com\/2022-abstract.pdf\"><em>Open File On External Site<\/em><\/a><\/p><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t<div class=\"elementor-toggle-item\">\n\t\t\t\t\t<div id=\"elementor-tab-title-3542\" class=\"elementor-tab-title\" data-tab=\"2\" role=\"tab\" aria-controls=\"elementor-tab-content-3542\" aria-expanded=\"false\">\n\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon elementor-toggle-icon-left\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-closed\"><i class=\"fas fa-caret-square-down\"><\/i><\/span>\n\t\t\t\t\t\t\t\t<span class=\"elementor-toggle-icon-opened\"><i class=\"elementor-toggle-icon-opened far fa-caret-square-up\"><\/i><\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<\/span>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\" class=\"elementor-toggle-title\">Additional Sources and References<\/a>\n\t\t\t\t\t<\/div>\n\n\t\t\t\t\t<div id=\"elementor-tab-content-3542\" class=\"elementor-tab-content elementor-clearfix\" data-tab=\"2\" role=\"tabpanel\" aria-labelledby=\"elementor-tab-title-3542\"><ul><li><span style=\"font-weight: 400;\">Acharya, U. R., Oh, S. L., Hagiwara, Y., Tan, J. H., Adam, M., Gertych, A., &amp;amp; Tan, R. S. (2017, August 24). A deep convolutional neural network model to classify heartbeats. Computers in Biology and Medicine. Retrieved December 29, 2021, from https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0010482517302810?casa_token=ufM7dWVQvzIAAAAA%3A6Q7840z1UyqkEDSc5HRGebPpdSi5el09lxikoaeQFj8SVlkSGdhFVaoG7bjfvYfMl7LgaxmaBj0<\/span><\/li><li><span style=\"font-weight: 400;\">Gulshan V;Peng L;Coram M;Stumpe MC;Wu D;Narayanaswamy A;Venugopalan S;Widner K;Madams T;Cuadros J;Kim R;Raman R;Nelson PC;Mega JL;Webster DR; (n.d.). Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. JAMA. Retrieved January 23, 2022, from https:\/\/pubmed.ncbi.nlm.nih.gov\/27898976\/<\/span><\/li><li><span style=\"font-weight: 400;\">K-nearest neighbor algorithm: Topics by science.gov. (n.d.). Retrieved January 23, 2022, from https:\/\/www.science.gov\/topicpages\/k\/k-nearest+neighbor+algorithm<\/span><\/li><li><span style=\"font-weight: 400;\">Lam, C., Yi, D., Guo, M., &amp; Lindsey, T. (2018, May 18). Automated detection of diabetic retinopathy using Deep Learning. AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on Translational Science. Retrieved January 23, 2022, from https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC5961805\/<\/span><\/li><li><span style=\"font-weight: 400;\">Nentwich, M. M., &amp; Ulbig, M. W. (2015, April 15). Diabetic retinopathy &#8211; ocular complications of diabetes mellitus. World journal of diabetes. Retrieved January 23, 2022, from https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC4398904\/<\/span><\/li><li><span style=\"font-weight: 400;\">Peterson, L. E. (n.d.). K-Nearest Neighbor. Scholarpedia. Retrieved December 29, 2021, from http:\/\/www.scholarpedia.org\/article\/K-nearest_neighbor\u00a0<\/span><\/li><li><span style=\"font-weight: 400;\">Saha, S. (2018, December 17). A comprehensive guide to convolutional neural networks\u200a-\u200athe eli5 way. Medium. Retrieved December 29, 2021, from https:\/\/towardsdatascience.com\/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53\u00a0<\/span><\/li><li><span style=\"font-weight: 400;\">Thorat, N. (2018, June 20). How to build a teachable machine with Tensorflow.js. Observable. Retrieved December 29, 2021, from https:\/\/observablehq.com\/@nsthorat\/how-to-build-a-teachable-machine-with-tensorflow-js)<\/span><\/li><li><span style=\"font-weight: 400;\">Two Way ANOVA Calculator. (n.d.). Retrieved January 23, 2022, from https:\/\/www.statskingdom.com\/two-way-anova-calculator.html<\/span><\/li><li><span style=\"font-weight: 400;\">Zhang, Z. (2016, June). Introduction to machine learning: K-Nearest Neighbors. Annals of translational medicine. Retrieved January 23, 2022, from https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC4916348\/ <\/span><\/li><\/ul><\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<div class=\"elementor-element elementor-element-a083e19 elementor-widget elementor-widget-spacer\" data-id=\"a083e19\" data-element_type=\"widget\" data-widget_type=\"spacer.default\">\n\t\t\t\t<div class=\"elementor-widget-container\">\n\t\t\t\t\t<div class=\"elementor-spacer\">\n\t\t\t<div class=\"elementor-spacer-inner\"><\/div>\n\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t<\/div>\n\t\t\t\t\t<\/div>\n\t\t<\/div>\n\t\t\t\t\t\t\t<\/div>\n\t\t<\/section>\n\t\t\t\t\t\t<\/div>\n\t\t\t\t\t<\/div>\n\t\t","protected":false},"excerpt":{"rendered":"<p>PROJECT SCIENCE FAIR USES MEDIBOUND WORKS WITH MOBILE Comparing the Efficiency of Novel Point of Care Approaches to Identifying Specific Stages of Diabetic Retinopathy Through the Use of Low-Cost Neural Networks and Deep Learning Solutions A Novel Study Conducted By Nicholas Harty and Aum Dhruv &#8211; (2021-2022) Prerequisites: EyePACS DR Retinal Imaging Classification Library 0 &hellip;<\/p>\n<p class=\"read-more\"> <a class=\"\" href=\"https:\/\/localhost\/medibound\/project\/\"> <span class=\"screen-reader-text\">Projects<\/span> Read More &raquo;<\/a><\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"","meta":{"ngg_post_thumbnail":0},"yoast_head":"<!-- This site is optimized with the Yoast SEO plugin v17.6 - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\r\n<title>Projects<\/title>\r\n<meta name=\"description\" content=\"A mobile app dedicated to advancing and progressing the health statistics.\" \/>\r\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\r\n<link rel=\"canonical\" href=\"https:\/\/localhost\/medibound\/project\/\" \/>\r\n<meta property=\"og:locale\" content=\"en_US\" \/>\r\n<meta property=\"og:type\" content=\"article\" \/>\r\n<meta property=\"og:title\" content=\"Projects\" \/>\r\n<meta property=\"og:description\" content=\"A mobile app dedicated to advancing and progressing the health statistics.\" \/>\r\n<meta property=\"og:url\" content=\"https:\/\/localhost\/medibound\/project\/\" \/>\r\n<meta property=\"og:site_name\" content=\"medibound\" \/>\r\n<meta property=\"article:publisher\" content=\"https:\/\/www.facebook.com\/medibound\" \/>\r\n<meta property=\"article:modified_time\" content=\"2022-06-28T14:27:08+00:00\" \/>\r\n<meta property=\"og:image\" content=\"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/nfc-data.png\" \/>\r\n\t<meta property=\"og:image:width\" content=\"1425\" \/>\r\n\t<meta property=\"og:image:height\" content=\"948\" \/>\r\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\r\n<meta name=\"twitter:site\" content=\"@medibound\" \/>\r\n<meta name=\"twitter:label1\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data1\" content=\"15 minutes\" \/>\r\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\r\n\t    \"@context\": \"https:\/\/schema.org\",\r\n\t    \"@graph\": [\r\n\t        {\r\n\t            \"@type\": \"Organization\",\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/#organization\",\r\n\t            \"name\": \"Medibound\",\r\n\t            \"url\": \"https:\/\/localhost\/medibound\/\",\r\n\t            \"sameAs\": [\r\n\t                \"https:\/\/www.facebook.com\/medibound\",\r\n\t                \"https:\/\/www.instagram.com\/medibound\/\",\r\n\t                \"https:\/\/www.youtube.com\/channel\/UCSI3uXSACHr70QVVUbp3hNw\",\r\n\t                \"https:\/\/twitter.com\/medibound\"\r\n\t            ],\r\n\t            \"logo\": {\r\n\t                \"@type\": \"ImageObject\",\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#logo\",\r\n\t                \"inLanguage\": \"en-US\",\r\n\t                \"url\": \"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/mediboundlogo-Recovered-1024x1024.png\",\r\n\t                \"contentUrl\": \"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/mediboundlogo-Recovered-1024x1024.png\",\r\n\t                \"width\": 1024,\r\n\t                \"height\": 1024,\r\n\t                \"caption\": \"Medibound\"\r\n\t            },\r\n\t            \"image\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#logo\"\r\n\t            }\r\n\t        },\r\n\t        {\r\n\t            \"@type\": \"WebSite\",\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/#website\",\r\n\t            \"url\": \"https:\/\/localhost\/medibound\/\",\r\n\t            \"name\": \"medibound\",\r\n\t            \"description\": \"Your Medical Data In Your Hands\",\r\n\t            \"publisher\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#organization\"\r\n\t            },\r\n\t            \"potentialAction\": [\r\n\t                {\r\n\t                    \"@type\": \"SearchAction\",\r\n\t                    \"target\": {\r\n\t                        \"@type\": \"EntryPoint\",\r\n\t                        \"urlTemplate\": \"https:\/\/localhost\/medibound\/?s={search_term_string}\"\r\n\t                    },\r\n\t                    \"query-input\": \"required name=search_term_string\"\r\n\t                }\r\n\t            ],\r\n\t            \"inLanguage\": \"en-US\"\r\n\t        },\r\n\t        {\r\n\t            \"@type\": [\r\n\t                \"WebPage\",\r\n\t                \"ProfilePage\"\r\n\t            ],\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/project\/#webpage\",\r\n\t            \"url\": \"https:\/\/localhost\/medibound\/project\/\",\r\n\t            \"name\": \"Projects\",\r\n\t            \"isPartOf\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#website\"\r\n\t            },\r\n\t            \"datePublished\": \"2021-12-12T07:05:52+00:00\",\r\n\t            \"dateModified\": \"2022-06-28T14:27:08+00:00\",\r\n\t            \"description\": \"A mobile app dedicated to advancing and progressing the health statistics.\",\r\n\t            \"breadcrumb\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/project\/#breadcrumb\"\r\n\t            },\r\n\t            \"inLanguage\": \"en-US\",\r\n\t            \"potentialAction\": [\r\n\t                {\r\n\t                    \"@type\": \"ReadAction\",\r\n\t                    \"target\": [\r\n\t                        \"https:\/\/localhost\/medibound\/project\/\"\r\n\t                    ]\r\n\t                }\r\n\t            ]\r\n\t        },\r\n\t        {\r\n\t            \"@type\": \"BreadcrumbList\",\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/project\/#breadcrumb\",\r\n\t            \"itemListElement\": [\r\n\t                {\r\n\t                    \"@type\": \"ListItem\",\r\n\t                    \"position\": 1,\r\n\t                    \"name\": \"Home\",\r\n\t                    \"item\": \"https:\/\/localhost\/medibound\/\"\r\n\t                },\r\n\t                {\r\n\t                    \"@type\": \"ListItem\",\r\n\t                    \"position\": 2,\r\n\t                    \"name\": \"Projects\"\r\n\t                }\r\n\t            ]\r\n\t        },\r\n\t        {\r\n\t            \"@type\": \"Article\",\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/project\/#article\",\r\n\t            \"isPartOf\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/project\/#webpage\"\r\n\t            },\r\n\t            \"author\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#\/schema\/person\/2033b810daa6a3eb77b9843cbbd67d57\"\r\n\t            },\r\n\t            \"headline\": \"Projects\",\r\n\t            \"datePublished\": \"2021-12-12T07:05:52+00:00\",\r\n\t            \"dateModified\": \"2022-06-28T14:27:08+00:00\",\r\n\t            \"mainEntityOfPage\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/project\/#webpage\"\r\n\t            },\r\n\t            \"wordCount\": 3358,\r\n\t            \"publisher\": {\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#organization\"\r\n\t            },\r\n\t            \"inLanguage\": \"en-US\"\r\n\t        },\r\n\t        {\r\n\t            \"@type\": \"Person\",\r\n\t            \"@id\": \"https:\/\/localhost\/medibound\/#\/schema\/person\/2033b810daa6a3eb77b9843cbbd67d57\",\r\n\t            \"name\": \"nickyhero965\",\r\n\t            \"image\": {\r\n\t                \"@type\": \"ImageObject\",\r\n\t                \"@id\": \"https:\/\/localhost\/medibound\/#personlogo\",\r\n\t                \"inLanguage\": \"en-US\",\r\n\t                \"url\": \"https:\/\/secure.gravatar.com\/avatar\/e44a14002c03b842237f11270de4071c?s=96&d=mm&r=g\",\r\n\t                \"contentUrl\": \"https:\/\/secure.gravatar.com\/avatar\/e44a14002c03b842237f11270de4071c?s=96&d=mm&r=g\",\r\n\t                \"caption\": \"nickyhero965\"\r\n\t            },\r\n\t            \"sameAs\": [\r\n\t                \"http:\/\/localhost\/medibound\"\r\n\t            ]\r\n\t        }\r\n\t    ]\r\n\t}<\/script>\r\n<!-- \/ Yoast SEO plugin. -->","yoast_head_json":{"title":"Projects","description":"A mobile app dedicated to advancing and progressing the health statistics.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/localhost\/medibound\/project\/","og_locale":"en_US","og_type":"article","og_title":"Projects","og_description":"A mobile app dedicated to advancing and progressing the health statistics.","og_url":"https:\/\/localhost\/medibound\/project\/","og_site_name":"medibound","article_publisher":"https:\/\/www.facebook.com\/medibound","article_modified_time":"2022-06-28T14:27:08+00:00","og_image":[{"width":1425,"height":948,"url":"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/nfc-data.png","type":"image\/png"}],"twitter_card":"summary_large_image","twitter_site":"@medibound","twitter_misc":{"Est. reading time":"15 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Organization","@id":"https:\/\/localhost\/medibound\/#organization","name":"Medibound","url":"https:\/\/localhost\/medibound\/","sameAs":["https:\/\/www.facebook.com\/medibound","https:\/\/www.instagram.com\/medibound\/","https:\/\/www.youtube.com\/channel\/UCSI3uXSACHr70QVVUbp3hNw","https:\/\/twitter.com\/medibound"],"logo":{"@type":"ImageObject","@id":"https:\/\/localhost\/medibound\/#logo","inLanguage":"en-US","url":"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/mediboundlogo-Recovered-1024x1024.png","contentUrl":"https:\/\/localhost\/medibound\/wp-content\/uploads\/2021\/11\/mediboundlogo-Recovered-1024x1024.png","width":1024,"height":1024,"caption":"Medibound"},"image":{"@id":"https:\/\/localhost\/medibound\/#logo"}},{"@type":"WebSite","@id":"https:\/\/localhost\/medibound\/#website","url":"https:\/\/localhost\/medibound\/","name":"medibound","description":"Your Medical Data In Your Hands","publisher":{"@id":"https:\/\/localhost\/medibound\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/localhost\/medibound\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":["WebPage","ProfilePage"],"@id":"https:\/\/localhost\/medibound\/project\/#webpage","url":"https:\/\/localhost\/medibound\/project\/","name":"Projects","isPartOf":{"@id":"https:\/\/localhost\/medibound\/#website"},"datePublished":"2021-12-12T07:05:52+00:00","dateModified":"2022-06-28T14:27:08+00:00","description":"A mobile app dedicated to advancing and progressing the health statistics.","breadcrumb":{"@id":"https:\/\/localhost\/medibound\/project\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/localhost\/medibound\/project\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/localhost\/medibound\/project\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/localhost\/medibound\/"},{"@type":"ListItem","position":2,"name":"Projects"}]},{"@type":"Article","@id":"https:\/\/localhost\/medibound\/project\/#article","isPartOf":{"@id":"https:\/\/localhost\/medibound\/project\/#webpage"},"author":{"@id":"https:\/\/localhost\/medibound\/#\/schema\/person\/2033b810daa6a3eb77b9843cbbd67d57"},"headline":"Projects","datePublished":"2021-12-12T07:05:52+00:00","dateModified":"2022-06-28T14:27:08+00:00","mainEntityOfPage":{"@id":"https:\/\/localhost\/medibound\/project\/#webpage"},"wordCount":3358,"publisher":{"@id":"https:\/\/localhost\/medibound\/#organization"},"inLanguage":"en-US"},{"@type":"Person","@id":"https:\/\/localhost\/medibound\/#\/schema\/person\/2033b810daa6a3eb77b9843cbbd67d57","name":"nickyhero965","image":{"@type":"ImageObject","@id":"https:\/\/localhost\/medibound\/#personlogo","inLanguage":"en-US","url":"https:\/\/secure.gravatar.com\/avatar\/e44a14002c03b842237f11270de4071c?s=96&d=mm&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/e44a14002c03b842237f11270de4071c?s=96&d=mm&r=g","caption":"nickyhero965"},"sameAs":["http:\/\/localhost\/medibound"]}]}},"_links":{"self":[{"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/pages\/864"}],"collection":[{"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/comments?post=864"}],"version-history":[{"count":394,"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/pages\/864\/revisions"}],"predecessor-version":[{"id":1970,"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/pages\/864\/revisions\/1970"}],"wp:attachment":[{"href":"https:\/\/localhost\/medibound\/wp-json\/wp\/v2\/media?parent=864"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}